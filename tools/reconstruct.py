#!/usr/bin/env python

import argparse

import matplotlib.pyplot as plt

import torch

from torchvision.transforms import transforms

import sys
sys.path.append("./")

import utils
import models.builer as builder
import dataloader

import os

os.environ["CUDA_VISIBLE_DEVICES"] = "0"
DIMS = 128

ids = [(0.012297041714191437, 11), (0.012373152188956738, 102), (0.012542938813567162, 31), (0.012557018548250198, 227), (0.012596366927027702, 79)]
list_of_imgs = [x[1] for x in ids]


def get_args():
    # parse the args
    print('=> parse the args ...')
    parser = argparse.ArgumentParser(description='Trainer for auto encoder')
    parser.add_argument('--arch', default='vgg16', type=str, 
                        help='backbone architechture')
    parser.add_argument('--resume', type=str)
    parser.add_argument('--val_list', type=str)              
    
    args = parser.parse_args()

    args.parallel = 0
    args.batch_size = 1
    args.workers = 0

    return args

def main(args):
    
    print('=> torch version : {}'.format(torch.__version__))

    utils.init_seeds(1, cuda_deterministic=False)

    print('=> modeling the network ...')
    model = builder.BuildAutoEncoder(args)     
    total_params = sum(p.numel() for p in model.parameters())
    print('=> num of params: {} ({}M)'.format(total_params, int(total_params * 4 / (1024*1024))))

    print('=> loading pth from {} ...'.format(args.resume))
    utils.load_dict(args.resume, model)
    
    print('=> building the dataloader ...')
    train_loader = dataloader.val_loader(args)

    plt.figure(figsize=(16, 9))

    model.eval()
    print('=> reconstructing ...')
    with torch.no_grad():
        for i, (input, target) in enumerate(train_loader):
            if i in list_of_imgs:
                input = input.cuda(non_blocking=True)
                target = target.cuda(non_blocking=True)

                output = model(input, mrl_dims=[DIMS])
                output = output[0]
                input = transforms.ToPILImage()(input.squeeze().cpu())
                output = transforms.ToPILImage()(output.squeeze().cpu())

                plt.subplot(8,16,2*i+1, xticks=[], yticks=[])
                plt.imshow(input)

                plt.subplot(8,16,2*i+2, xticks=[], yticks=[])
                plt.imshow(output)

                # if i == 63:
                #     break

                plt.savefig('figs/apr3/reconstruction_'+str(DIMS)+'_apr3_'+str(i)+'.jpg')

if __name__ == '__main__':

    args = get_args()

    main(args)




'''
[(0.012297041714191437, 11), (0.012373152188956738, 102), (0.012542938813567162, 31), (0.012557018548250198, 227), (0.012596366927027702, 79), (0.01262533850967884, 151), (0.012636320665478706, 48), (0.012637963518500328, 46), (0.012665222398936749, 224), (0.012679078616201878, 86), (0.012679829262197018, 16), (0.012724604457616806, 193), (0.012766584753990173, 149), (0.012822973541915417, 36), (0.012828855775296688, 170), (0.012844700366258621, 44), (0.0128546841442585, 233), (0.012875466607511044, 123), (0.012884723953902721, 194), (0.012888800352811813, 105), (0.012892112135887146, 172), (0.012963899411261082, 183), (0.01297916192561388, 58), (0.012988428585231304, 39), (0.012995571829378605, 52), (0.013019811362028122, 120), (0.01302113477140665, 181), (0.01303292065858841, 27), (0.013041076250374317, 70), (0.013046377338469028, 215), (0.013067671097815037, 1), (0.013078640215098858, 80), (0.013092258013784885, 221), (0.013104049488902092, 127), (0.01310507208108902, 220), (0.013105510734021664, 237), (0.013112748041749, 45), (0.013118098489940166, 10), (0.013130043633282185, 15), (0.01313093677163124, 76), (0.013139963150024414, 81), (0.013140981085598469, 203), (0.013164715841412544, 197), (0.013178935274481773, 90), (0.013179953210055828, 94), (0.013183807954192162, 148), (0.013190828263759613, 225), (0.013194821774959564, 53), (0.013200693763792515, 67), (0.013200923800468445, 78), (0.013201361522078514, 205), (0.013201466761529446, 146), (0.013202180154621601, 143), (0.01321655884385109, 87), (0.013216991908848286, 168), (0.013228080235421658, 33), (0.013240677304565907, 212), (0.013250334188342094, 204), (0.013258070684969425, 68), (0.013262592256069183, 136), (0.01328626275062561, 61), (0.013292078860104084, 223), (0.013295001350343227, 117), (0.013295711949467659, 50), (0.013296484015882015, 152), (0.013300093822181225, 62), (0.013306398876011372, 99), (0.013307766057550907, 83), (0.013314594514667988, 85), (0.013319256715476513, 137), (0.0133207393810153, 188), (0.013326434418559074, 41), (0.013339693658053875, 201), (0.013339804485440254, 145), (0.01334487646818161, 214), (0.013345476239919662, 65), (0.013348993845283985, 69), (0.01335562951862812, 97), (0.013356237672269344, 147), (0.013364817947149277, 40), (0.013367877341806889, 209), (0.013373062945902348, 198), (0.013397123664617538, 142), (0.013401777483522892, 164), (0.013402088545262814, 235), (0.01341200340539217, 140), (0.01341552846133709, 199), (0.013440110720694065, 186), (0.013442485593259335, 26), (0.013443989679217339, 159), (0.013445919379591942, 3), (0.01344753336161375, 19), (0.013452241197228432, 24), (0.0134554672986269, 106), (0.013464565388858318, 2), (0.013473805971443653, 182), (0.013475727289915085, 208), (0.013482813723385334, 91), (0.013497095555067062, 213), (0.013497401028871536, 234)]
'''